"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.getNextIdGroup = exports.findNextItemIndex = exports.default = void 0;

var _shared = require("@rpldy/shared");

var _processBatchItems = _interopRequireDefault(require("./processBatchItems"));

var _batchHelpers = require("./batchHelpers");

var _itemHelpers = require("./itemHelpers");

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const getIsItemInActiveRequest = (queue, itemId) => {
  return queue.getState().activeIds // $FlowIssue - no flat
  .flat().includes(itemId);
};

const getIsItemReady = item => item.state === _shared.FILE_STATES.ADDED;

const findNextItemIndex = queue => {
  const state = queue.getState(),
        itemQueue = state.itemQueue,
        items = state.items;
  let index = 0,
      nextId = itemQueue[index]; //find item that isnt already in an active request and belongs to a "ready" batch

  while (nextId && (getIsItemInActiveRequest(queue, nextId) || !(0, _batchHelpers.getIsItemBatchReady)(queue, nextId) || !getIsItemReady(items[nextId]))) {
    index += 1;
    nextId = itemQueue[index];
  }

  return nextId ? index : -1;
};

exports.findNextItemIndex = findNextItemIndex;

const getNextIdGroup = queue => {
  const itemQueue = queue.getState().itemQueue;
  const nextItemIndex = findNextItemIndex(queue);
  let nextId = itemQueue[nextItemIndex],
      nextGroup;

  if (nextId) {
    const batchData = (0, _batchHelpers.getBatchDataFromItemId)(queue, nextId);
    const batchId = batchData.batch.id,
          groupMax = batchData.batchOptions.maxGroupSize || 0;

    if (batchData.batchOptions.grouped && groupMax > 1) {
      nextGroup = [];
      let nextBelongsToSameBatch = true; //dont group files from different batches

      while (nextGroup.length < groupMax && nextBelongsToSameBatch) {
        nextGroup.push(nextId);
        nextId = itemQueue[nextItemIndex + nextGroup.length];
        nextBelongsToSameBatch = nextId && (0, _itemHelpers.isItemBelongsToBatch)(queue, nextId, batchId);
      }
    } else {
      nextGroup = [nextId];
    }
  }

  return nextGroup;
};

exports.getNextIdGroup = getNextIdGroup;

const updateItemsAsActive = (queue, ids) => {
  queue.updateState(state => {
    //immediately mark items as active to support concurrent uploads without getting into infinite loops
    state.activeIds = state.activeIds.concat(ids);
  });
};

const processNextWithBatch = (queue, ids) => {
  let newBatchP;
  updateItemsAsActive(queue, ids);

  if ((0, _batchHelpers.isNewBatchStarting)(queue, ids[0])) {
    newBatchP = (0, _batchHelpers.loadNewBatchForItem)(queue, ids[0]).then(allowBatch => {
      let cancelled = !allowBatch;

      if (cancelled) {
        (0, _batchHelpers.cancelBatchForItem)(queue, ids[0]);
        processNext(queue);
      }

      return cancelled;
    }).catch(err => {
      _shared.logger.debugLog("uploader.processor: encountered error while preparing batch for request", err);

      (0, _batchHelpers.failBatchForItem)(queue, ids[0], err);
      processNext(queue);
      return true;
    });
  } else {
    newBatchP = Promise.resolve(false);
  }

  return newBatchP;
};

const processNext = queue => {
  //using promise only for testing purposes, actual code doesnt require awaiting on this method
  let processPromise;
  const ids = getNextIdGroup(queue);

  if (ids) {
    const currentCount = queue.getCurrentActiveCount(),
          {
      concurrent = 0,
      maxConcurrent = 0
    } = queue.getOptions();

    if (!currentCount || concurrent && currentCount < maxConcurrent) {
      _shared.logger.debugLog("uploader.processor: Processing next upload - ", {
        ids,
        currentCount
      });

      processPromise = processNextWithBatch(queue, ids).then(failedOrCancelled => {
        if (!failedOrCancelled) {
          (0, _processBatchItems.default)(queue, ids, processNext);

          if (concurrent) {
            //concurrent process next immediately (otherwise async event callbacks will hang processing next until they complete)
            processNext(queue);
          }
        }
      });
    }
  }

  return processPromise;
};

var _default = processNext;
exports.default = _default;